{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script loads subjects with probes, gets evoked activity for all units, analyzes responsiveness, and saves the files in each subject's data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import gspread\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal, fftpack, stats, ndimage\n",
    "import statsmodels.stats.multitest as multitest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'C:\\Users\\lesliec\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbd_eeg.tbd_eeg.data_analysis.eegutils import EEGexp\n",
    "from tbd_eeg.tbd_eeg.data_analysis.Utilities.utilities import (\n",
    "    get_stim_events,\n",
    "    get_evoked_traces,\n",
    "    get_evoked_firing_rates,\n",
    "    find_nearest_ind\n",
    ")\n",
    "from allensdk.brain_observatory.ecephys.lfp_subsampling.subsampling import remove_lfp_offset\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CCF for identifying cortical areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache(resolution=10)\n",
    "str_tree = mcc.get_structure_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Zap_Zip-log_exp to get metadata for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gc = gspread.service_account() # need a key file to access the account\n",
    "_sh = _gc.open('Zap_Zip-log_exp') # open the spreadsheet\n",
    "_df = pd.DataFrame(_sh.sheet1.get()) # load the first worksheet\n",
    "zzmetadata = _df.T.set_index(0).T # put it in a nicely formatted dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define areas of interest to plot population activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_of_interest = {\n",
    "    'MO': [\n",
    "        'MOp1', 'MOp2/3', 'MOp5', 'MOp6a', 'MOp6b',\n",
    "        'MOs1', 'MOs2/3', 'MOs5', 'MOs6a', 'MOs6b'\n",
    "    ],\n",
    "    'ACA': [\n",
    "        'ACAd1', 'ACAd2/3', 'ACAd5', 'ACAd6a', 'ACAd6b',\n",
    "        'ACAv1', 'ACAv2/3', 'ACAv5', 'ACAv6a', 'ACAv6b'\n",
    "    ],\n",
    "    'SS': [\n",
    "        'SSp-bfd1', 'SSp-bfd2/3', 'SSp-bfd4', 'SSp-bfd5', 'SSp-bfd6a', 'SSp-bfd6b',\n",
    "        'SSp-ll1', 'SSp-ll2/3', 'SSp-ll4', 'SSp-ll5', 'SSp-ll6a', 'SSp-ll6b',\n",
    "        'SSp-tr1', 'SSp-tr2/3', 'SSp-tr4', 'SSp-tr5', 'SSp-tr6a', 'SSp-tr6b'\n",
    "    ],\n",
    "    'VIS': [\n",
    "        'VISp1', 'VISp2/3', 'VISp4', 'VISp5', 'VISp6a', 'VISp6b',\n",
    "        'VISam1', 'VISam2/3', 'VISam4', 'VISam5', 'VISam6a', 'VISam6b',\n",
    "        'VISpm1', 'VISpm2/3', 'VISpm4', 'VISpm5', 'VISpm6a', 'VISpm6b',\n",
    "        'VISrl1', 'VISrl2/3', 'VISrl4', 'VISrl5', 'VISrl6a', 'VISrl6b',\n",
    "    ],\n",
    "    'MO-TH': [\n",
    "        'AV', 'CL', 'MD', 'PO', 'RT', 'VAL', 'VPL', 'VPM', 'VM'\n",
    "    ],\n",
    "}\n",
    "\n",
    "area_colors = {\n",
    "    'MO': 'blue',\n",
    "    'ACA': 'deepskyblue',\n",
    "    'SS': 'blueviolet',\n",
    "    'VIS': 'green',\n",
    "    'MO-TH': 'steelblue',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_colors = {\n",
    "    'awake': (120/255, 156/255, 74/255),\n",
    "    'anesthetized': (130/255, 122/255, 163/255),\n",
    "    'recovery': (93/255, 167/255, 229/255)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_response(row, alpha=0.05):\n",
    "    if row['corr_pval'] < alpha and row['delta_spike_count'] > 0:\n",
    "        return 'excited'\n",
    "    elif row['corr_pval'] < alpha and row['delta_spike_count'] < 0:\n",
    "        return 'inhibited'\n",
    "    else:\n",
    "        return 'ns'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load subjects from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\lesliec\\OneDrive - Allen Institute\\data\\all_iso_subjects_wPROBES.json') as subjects_file:\n",
    "    multi_sub_dict = json.load(subjects_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Load fewer subjects for testing script ##\n",
    "with open(r'C:\\Users\\lesliec\\OneDrive - Allen Institute\\data\\TEST_iso_subjects_wPROBES.json') as subjects_file:\n",
    "    multi_sub_dict = json.load(subjects_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOs_superficial\n",
      "\n",
      " 546655\n",
      "Experiment type: electrical and sensory stimulation\n",
      "\n",
      " 575102\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 571619\n",
      "Experiment type: electrical stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      "\n",
      "MOs_deep\n",
      "\n",
      " 551399\n",
      "Experiment type: electrical stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 551397\n",
      "Experiment type: electrical and sensory stimulation\n",
      "Body camera file not found.\n",
      "Pupil camera file not found.\n",
      "\n",
      " 569062\n",
      "Experiment type: electrical and sensory stimulation\n",
      "\n",
      " 569068\n",
      "Experiment type: electrical and sensory stimulation\n",
      "\n",
      " 569069\n",
      "Experiment type: electrical and sensory stimulation\n",
      "\n",
      " 569064\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 569073\n",
      "Experiment type: electrical and sensory stimulation\n",
      "\n",
      " 571619\n",
      "Experiment type: electrical stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      "\n",
      "SSp_superficial\n",
      "\n",
      " 571620\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 586466\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 590479\n",
      "Experiment type: electrical stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 590480\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 590481\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      "\n",
      "SSp_deep\n",
      "\n",
      " 569073\n",
      "Experiment type: electrical stimulation\n",
      "\n",
      " 569072\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 571620\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 586466\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 590479\n",
      "Experiment type: electrical stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 590480\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      " 590481\n",
      "Experiment type: electrical and sensory stimulation\n",
      "SomnoSuite log file not found.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group, group_subs in multi_sub_dict.items():\n",
    "    print(group)\n",
    "    print('')\n",
    "    for mouse_num, mdata in group_subs.items():\n",
    "        print(' {}'.format(mouse_num))\n",
    "        mdata['exp'] = EEGexp(mdata['data_loc'], preprocess=False, make_stim_csv=False)\n",
    "        print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plotsdir = r'C:\\Users\\lesliec\\OneDrive - Allen Institute\\data\\plots\\manuscript_figs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_level = ['low', 'medium', 'high']\n",
    "test_states = ['awake', 'anesthetized']\n",
    "\n",
    "overwrite_existing_files = False\n",
    "rest_trials_only = True\n",
    "match_trial_nums = True\n",
    "\n",
    "raster_window = [-1.0, 1.0]\n",
    "response_window = {\n",
    "    'early': [0.002, 0.025],\n",
    "    'mid': [0.025, 0.15],\n",
    "    'late': [0.15, 0.3],\n",
    "}\n",
    "## For calculating SDF ##\n",
    "time_bin = 0.0001 # size of time bins (s)\n",
    "bins = np.arange(raster_window[0], raster_window[1] + time_bin, time_bin)\n",
    "timex = bins[:-1] + time_bin/2\n",
    "sigshort = 5 # Gaussian kernel length (Butovas&Schwarz2003 use short kernel for first excitatory response)\n",
    "siglong = 50 # Gaussian kernel length (Butovas&Schwarz2003 use long kernel for rest of response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data for all subjects and all units (RS & FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOs_superficial\n",
      "\n",
      " 546655\n",
      "  F:\\EEG_exp\\mouse546655\\estim_vis_2020-10-23_11-01-14\\experiment1\\recording1\\units_info_wresp_MOs_superficial.csv already exists, skipping analysis.\n",
      "\n",
      " 575102\n",
      "  F:\\EEG_exp\\mouse575102\\estim_vis_2021-06-03_11-25-01\\experiment1\\recording1\\units_info_wresp_MOs_superficial.csv already exists, skipping analysis.\n",
      "\n",
      " 571619\n",
      "  F:\\EEG_exp\\mouse571619\\estim2_2021-03-19_10-09-01\\experiment1\\recording1\\units_info_wresp_MOs_superficial.csv already exists, skipping analysis.\n",
      "\n",
      "MOs_deep\n",
      "\n",
      " 551399\n",
      "  F:\\EEG_exp\\mouse551399\\estim_2021-01-28_13-59-09\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 551397\n",
      "  F:\\EEG_exp\\mouse551397\\estim_vis_2021-02-11_10-45-23\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 569062\n",
      "  F:\\EEG_exp\\mouse569062\\estim_vis_2021-02-18_11-17-51\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 569068\n",
      "  F:\\EEG_exp\\mouse569068\\estim_vis_2021-03-04_10-51-38\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 569069\n",
      "  F:\\EEG_exp\\mouse569069\\estim_vis2_2021-03-12_10-52-44\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 569064\n",
      "  F:\\EEG_exp\\mouse569064\\estim_vis_2021-04-08_10-28-24\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 569073\n",
      "  F:\\EEG_exp\\mouse569073\\estim_vis_2021-04-15_10-27-22\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 571619\n",
      "  F:\\EEG_exp\\mouse571619\\estim2_2021-03-19_10-09-01\\experiment1\\recording1\\units_info_wresp_MOs_deep.csv already exists, skipping analysis.\n",
      "\n",
      "SSp_superficial\n",
      "\n",
      " 571620\n",
      "  F:\\EEG_exp\\mouse571620\\estim_vis_2021-05-13_11-33-47\\experiment1\\recording1\\units_info_wresp_SSp_superficial.csv already exists, skipping analysis.\n",
      "\n",
      " 586466\n",
      "  F:\\EEG_exp\\mouse586466\\estim_vis_2021-07-29_10-37-41\\experiment1\\recording1\\units_info_wresp_SSp_superficial.csv already exists, skipping analysis.\n",
      "\n",
      " 590479\n",
      "probeB\n",
      "probeF\n",
      "  Time to get evoked unit activity and save .pkl file: 0.96 min\n",
      "  Time to test responsive units and save .csv file: 0.39 min\n",
      "\n",
      " 590480\n",
      "probeB\n",
      "probeC\n",
      "probeF\n",
      "  Time to get evoked unit activity and save .pkl file: 1.46 min\n",
      "  Time to test responsive units and save .csv file: 0.30 min\n",
      "\n",
      " 590481\n",
      "probeB\n",
      "probeC\n",
      "probeF\n",
      "  Time to get evoked unit activity and save .pkl file: 1.01 min\n",
      "  Time to test responsive units and save .csv file: 0.29 min\n",
      "\n",
      "SSp_deep\n",
      "\n",
      " 569073\n",
      "  F:\\EEG_exp\\mouse569073\\estim_2021-04-16_10-42-44\\experiment1\\recording1\\units_info_wresp_SSp_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 569072\n",
      "  F:\\EEG_exp\\mouse569072\\estim_vis_2021-04-22_10-26-58\\experiment1\\recording1\\units_info_wresp_SSp_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 571620\n",
      "  F:\\EEG_exp\\mouse571620\\estim_vis_2021-05-13_11-33-47\\experiment1\\recording1\\units_info_wresp_SSp_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 586466\n",
      "  F:\\EEG_exp\\mouse586466\\estim_vis_2021-07-29_10-37-41\\experiment1\\recording1\\units_info_wresp_SSp_deep.csv already exists, skipping analysis.\n",
      "\n",
      " 590479\n",
      "probeB\n",
      "probeF\n",
      "  Time to get evoked unit activity and save .pkl file: 1.05 min\n",
      "  Time to test responsive units and save .csv file: 0.35 min\n",
      "\n",
      " 590480\n",
      "probeB\n",
      "probeC\n",
      "probeF\n",
      "  Time to get evoked unit activity and save .pkl file: 1.91 min\n",
      "  Time to test responsive units and save .csv file: 0.45 min\n",
      "\n",
      " 590481\n",
      "probeB\n",
      "probeC\n",
      "probeF\n",
      "  Time to get evoked unit activity and save .pkl file: 1.29 min\n",
      "  Time to test responsive units and save .csv file: 0.34 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group, group_subs in multi_sub_dict.items():\n",
    "    print(group)\n",
    "    print('')\n",
    "    for mouse_num, mdata in group_subs.items():\n",
    "        print(' {}'.format(mouse_num))\n",
    "        ## mdata['exp'].data_folder is the recording1 folder ##\n",
    "        \n",
    "        ## Set filenames and check if exist ##\n",
    "        evoked_folder = os.path.join(mdata['exp'], 'evoked_data')\n",
    "        if not os.path.exists(evoked_folder):\n",
    "            os.mkdir(evoked_folder)\n",
    "        fn_unit_activity = os.path.join(evoked_folder, 'units_evoked_activity_' + group + '.pkl')\n",
    "        fn_unit_info_csv = os.path.join(evoked_folder, 'units_info_' + group + '.csv')\n",
    "        fn_unit_resp_csv = os.path.join(evoked_folder, 'units_info_wresp_' + group + '.csv')\n",
    "        if overwrite_existing_files:\n",
    "            pass # will overwrite all subjects' files\n",
    "        else:\n",
    "            if os.path.exists(fn_unit_resp_csv):\n",
    "                print('  {} already exists, skipping analysis.\\n'.format(fn_unit_resp_csv))\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        ## Grab exp metadata from Zap_Zip-log_exp ##\n",
    "        exp_meta = zzmetadata[(\n",
    "            (zzmetadata['mouse_name'].str.contains(mdata['exp'].mouse)) &\n",
    "            (zzmetadata['exp_name'].str.contains(os.path.basename(os.path.dirname(mdata['exp'].experiment_folder))))\n",
    "        )].squeeze()\n",
    "        currentstr = exp_meta['Current (uA)'].replace(' ','')\n",
    "        currents_list = []\n",
    "        for char in currentstr.split('/'):\n",
    "            if char.isdecimal():\n",
    "                currents_list.append(char)\n",
    "\n",
    "        ## Load stim log and running signal ##\n",
    "        stim_log = pd.read_csv(mdata['exp'].stimulus_log_file)\n",
    "        stim_log = stim_log.astype({'parameter': str})\n",
    "        run_signal, run_timestamps = mdata['exp'].load_running()\n",
    "        \n",
    "        ## Load probe data ##\n",
    "        probe_list = [x.replace('_sorted', '') for x in mdata['exp'].experiment_data if 'probe' in x]\n",
    "        probe_locs = np.ones((len(probe_list)), dtype=bool)\n",
    "        probe_unit_data = {}\n",
    "        for pbi, probei in enumerate(probe_list):\n",
    "            print(probei)\n",
    "            probe_unit_data[probei] = {}\n",
    "            \n",
    "            ## Load probe_info.json ##\n",
    "            with open(mdata['exp'].ephys_params[probei]['probe_info']) as data_file:\n",
    "                data = json.load(data_file)\n",
    "            npx_allch = np.array(data['channel'])\n",
    "            surface_ch = int(data['surface_channel'])\n",
    "            allch_z = np.array(data['vertical_pos'])\n",
    "            ref_mask = np.array(data['mask'])\n",
    "            npx_chs = np.array([x for x in npx_allch if ref_mask[x] and x <= surface_ch])\n",
    "            probe_unit_data[probei]['ch_depths'] = allch_z[surface_ch] - allch_z\n",
    "            \n",
    "            ## Select units and get peak chs ##\n",
    "            select_units, peak_chs, unit_metrics = mdata['exp'].get_probe_units(probei)\n",
    "            unit_metrics['cell_type'] = unit_metrics['duration'].apply(lambda x: 'FS' if x <= 0.4 else 'RS')\n",
    "            ## Sort units ##\n",
    "            probe_unit_data[probei]['units'] = select_units[np.squeeze(np.argsort(peak_chs))]\n",
    "            probe_unit_data[probei]['chs'] = peak_chs[np.squeeze(np.argsort(peak_chs))]\n",
    "            probe_unit_data[probei]['cell_type'] = unit_metrics['cell_type'].values[np.squeeze(np.argsort(peak_chs))]\n",
    "            if 'area' in unit_metrics.columns:\n",
    "                probe_unit_data[probei]['areas'] = unit_metrics.area.values[np.squeeze(np.argsort(peak_chs))]\n",
    "            else:\n",
    "                print('  {} unit metrics file does not have area assignments.'.format(probei))\n",
    "                probe_locs[pbi] = False\n",
    "                continue\n",
    "            ## Load spike times and cluster ids ##\n",
    "            probe_unit_data[probei]['spike_times'] = np.load(mdata['exp'].ephys_params[probei]['spike_times'])\n",
    "            probe_unit_data[probei]['spike_clusters'] = np.load(mdata['exp'].ephys_params[probei]['spike_clusters'])\n",
    "        \n",
    "        if probe_locs.any():\n",
    "            pass\n",
    "        else:\n",
    "            print('  NO area assignments for any probes, not analyzing.')\n",
    "            continue\n",
    "        \n",
    "        ## Get trial times ##\n",
    "        all_event_times = {}\n",
    "        for leveli, parami in zip(current_level, currents_list):\n",
    "            all_event_times[leveli] = {}\n",
    "            for statei in test_states:\n",
    "                sweeps = mdata['states'][statei]\n",
    "                if sweeps:\n",
    "                    state_events = []\n",
    "                    for sweepi in sweeps:\n",
    "                        events = get_stim_events(stim_log, 'biphasic', parami, sweepi)\n",
    "                        if len(events) == 0:\n",
    "                            continue\n",
    "                        state_events.append(events)\n",
    "                    state_events = np.concatenate(state_events)\n",
    "                    ## Get mean speed ##\n",
    "                    rinds = np.arange(-int(0.5 * 100), int(0.5 * 100))\n",
    "                    event_inds = np.array([find_nearest_ind(run_timestamps, x) for x in state_events])\n",
    "                    mean_speed = np.mean(run_signal[np.repeat([rinds], len(event_inds), axis=0).T + event_inds], axis=0)\n",
    "                    if rest_trials_only:\n",
    "                        all_event_times[leveli][statei] = state_events[mean_speed == 0]\n",
    "                    else:\n",
    "                        all_event_times[leveli][statei] = state_events\n",
    "        \n",
    "        ## Get unit info and evoked activity (spikes and firing rate), save files ##\n",
    "        start = time.time()\n",
    "        all_units_info = []\n",
    "        unit_activity = {}\n",
    "        for probei, unit_data in probe_unit_data.items():\n",
    "            if 'areas' not in unit_data.keys():\n",
    "                print('  not including units from {}...no area assignments.'.format(probei))\n",
    "                continue\n",
    "            for unitind, uniti in enumerate(unit_data['units']):\n",
    "                unit_name = probei[-1] + str(uniti)\n",
    "                unit_info = [] # unit_id, cell_type, depth, region, parent\n",
    "                unit_activity[unit_name] = {}\n",
    "                ## Gather unit info ##\n",
    "                unit_info.append(unit_name) ## get unit_id ##\n",
    "                unit_info.append(unit_data['cell_type'][unitind]) ## get cell_type ##\n",
    "                unit_info.append(unit_data['ch_depths'][unit_data['chs'][unitind]]) ## get depth ##\n",
    "                unit_region = unit_data['areas'][unitind]\n",
    "                unit_info.append(unit_region) ## get region ##\n",
    "                parent_region = [key for key in list(areas_of_interest.keys()) if unit_region in areas_of_interest[key]]\n",
    "                if len(parent_region) == 1:\n",
    "                    unit_info.append(parent_region[0])\n",
    "                else:\n",
    "                    unit_info.append('notROI')\n",
    "                \n",
    "                ## Get evoked spikes and SDFs ##\n",
    "                spikesi = np.squeeze(unit_data['spike_times'][unit_data['spike_clusters'] == uniti])\n",
    "                baselineFR = np.zeros((len(test_states), len(current_level)), dtype=float)\n",
    "                for jj, leveli in enumerate(current_level):\n",
    "                    NUM_TRIALS = min([len(all_event_times[leveli][x]) for x in test_states])\n",
    "                    unit_activity[unit_name][leveli] = {}\n",
    "                    for ii, statei in enumerate(test_states):\n",
    "                        unit_activity[unit_name][leveli][statei] = {}\n",
    "                        if match_trial_nums:\n",
    "                            events = all_event_times[leveli][statei][:NUM_TRIALS]\n",
    "                        else:\n",
    "                            events = all_event_times[leveli][statei]\n",
    "                        ## Event spike raster ##\n",
    "                        event_raster = []\n",
    "                        for eventi in events:\n",
    "                            spikeinds = np.nonzero(\n",
    "                                (spikesi > eventi + raster_window[0]) & (spikesi < eventi + raster_window[1]))[0]\n",
    "                            event_raster.append(spikesi[spikeinds] - eventi)\n",
    "                        ## Evoked firing rate ##\n",
    "                        spike_counts, edges = np.histogram(np.concatenate(event_raster), bins)\n",
    "                        firing_rate = spike_counts / (time_bin * len(events))\n",
    "                        ## Store unit activity ##\n",
    "                        unit_activity[unit_name][leveli][statei]['trial_count'] = len(events)\n",
    "                        unit_activity[unit_name][leveli][statei]['event_spikes'] = event_raster\n",
    "                        unit_activity[unit_name][leveli][statei]['SDFshort'] = [\n",
    "                            timex, ndimage.gaussian_filter(firing_rate, sigma=sigshort, output=float)]\n",
    "                        unit_activity[unit_name][leveli][statei]['SDFlong'] = [\n",
    "                            timex, ndimage.gaussian_filter(firing_rate, sigma=siglong, output=float)]\n",
    "                        ## Get baseline firing rate ##\n",
    "                        baselineFR[ii,jj] = np.mean(firing_rate[timex < 0])\n",
    "                unit_info.append(np.mean(baselineFR, axis=1)[0]) ## awake BLFR ##\n",
    "                unit_info.append(np.mean(baselineFR, axis=1)[1]) ## anesthetized BLFR ##\n",
    "                ## Add unit_info to all_units_info ##\n",
    "                all_units_info.append(unit_info)\n",
    "\n",
    "        all_units_info_df = pd.DataFrame(\n",
    "            all_units_info, columns=['unit_id', 'cell_type', 'depth', 'region', 'parent', 'BLFR_awake', 'BLFR_anesthetized'])\n",
    "        ## Save the files to mouse's recordingX folder ##\n",
    "        pickle.dump(unit_activity, open(fn_unit_activity, 'wb'))\n",
    "        all_units_info_df.to_csv(fn_unit_info_csv, index=False)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('  Time to get evoked unit activity and save .pkl file: {:.2f} min'.format((end-start)/60))\n",
    "        del unit_info\n",
    "        \n",
    "        start = time.time()\n",
    "        ## Loop through all units to get responsiveness stats and save ##\n",
    "        unit_response_stats = []\n",
    "        for ind, row in all_units_info_df.iterrows():\n",
    "            for leveli in current_level:\n",
    "                for statei in test_states:\n",
    "                    uniti_activity = unit_activity[row.unit_id][leveli][statei]\n",
    "                    for window, rwin in response_window.items():\n",
    "                        unit_info = row.tolist()\n",
    "                        unit_info.extend([leveli, statei, window]) ## add stim level, state, response_stage ##\n",
    "\n",
    "                        ## Responsive p-value and spike count difference ##\n",
    "                        pre_spcounts = np.zeros(uniti_activity['trial_count'], dtype=int)\n",
    "                        post_spcounts = np.zeros(uniti_activity['trial_count'], dtype=int)\n",
    "                        for j, event_spikes in enumerate(uniti_activity['event_spikes']):\n",
    "                            pre_spcounts[j] = np.sum((event_spikes >= -rwin[1]) & (event_spikes <= -rwin[0]))\n",
    "                            post_spcounts[j] = np.sum((event_spikes >= rwin[0]) & (event_spikes <= rwin[1]))\n",
    "                        wstat, pval = stats.wilcoxon(x=post_spcounts, y=pre_spcounts, zero_method='zsplit')\n",
    "                        spcount = np.mean(post_spcounts) - np.mean(pre_spcounts)\n",
    "                        unit_info.extend([spcount, pval]) ## spike count and p-value ##\n",
    "\n",
    "                        ## Get firing rate for window ##\n",
    "                        testinds = np.nonzero((timex > rwin[0]) & (timex < rwin[1]))[0]\n",
    "                        SDFsh = uniti_activity['SDFshort'][1][testinds]\n",
    "                        SDFl = uniti_activity['SDFlong'][1][testinds]\n",
    "                        ublfr = row['BLFR_' + statei]\n",
    "                        if window == 'early':\n",
    "                            peaks, props = signal.find_peaks(SDFsh, height=ublfr)\n",
    "                            if len(props['peak_heights']) > 0:\n",
    "                                unit_info.append(np.max(props['peak_heights']))\n",
    "                            else:\n",
    "                                unit_info.append(np.nan)\n",
    "                        elif window == 'mid':\n",
    "                            unit_info.append(np.mean(SDFsh))\n",
    "                        elif window == 'late':\n",
    "                            peaks, props = signal.find_peaks(SDFl, height=ublfr)\n",
    "                            if len(props['peak_heights']) > 0:\n",
    "                                unit_info.append(np.max(props['peak_heights']))\n",
    "                            else:\n",
    "                                unit_info.append(np.nan)\n",
    "\n",
    "                        ## Store unit metrics ##\n",
    "                        unit_response_stats.append(unit_info)\n",
    "        all_unit_stats = pd.DataFrame(unit_response_stats, columns=[\n",
    "            'unit_id', 'cell_type', 'depth', 'region', 'parent', 'BLFR_awake', 'BLFR_anesthetized',\n",
    "            'stim_level', 'state', 'response_stage', 'delta_spike_count', 'pval', 'evokedFR',\n",
    "        ])\n",
    "        ## Adjust p-values for mulitple comparisons ##\n",
    "        original_pvals = all_unit_stats.pval.values\n",
    "        rej, corr_pvals = multitest.fdrcorrection(original_pvals)\n",
    "        all_unit_stats['corr_pval'] = corr_pvals\n",
    "        ## Classify response (excited/inhibited) (default alpha=0.05) ##\n",
    "        all_unit_stats['response_type'] = all_unit_stats.apply(lambda row: classify_response(row), axis=1)\n",
    "        ## Save the files ##\n",
    "        all_unit_stats.to_csv(fn_unit_resp_csv, index=False)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('  Time to test responsive units and save .csv file: {:.2f} min'.format((end-start)/60))\n",
    "            \n",
    "        ### After each subject, delete common variables ###\n",
    "        del stim_log\n",
    "        del run_signal\n",
    "        del run_timestamps\n",
    "        del probe_unit_data\n",
    "        del all_event_times\n",
    "        del all_units_info\n",
    "        del all_units_info_df\n",
    "        del unit_activity\n",
    "        del unit_response_stats\n",
    "        del all_unit_stats\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbd1",
   "language": "python",
   "name": "tbd1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
