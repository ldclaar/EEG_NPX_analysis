{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'C:\\Users\\lesliec\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbd_eeg.tbd_eeg.data_analysis.eegutils import EEGexp\n",
    "from ecephys_spike_sorting.ecephys_spike_sorting.modules.quality_metrics import *\n",
    "from ecephys_spike_sorting.ecephys_spike_sorting.common.utils import load_kilosort_data\n",
    "from ecephys_spike_sorting.ecephys_spike_sorting.common.epoch import Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions from metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_pcs(unit_id,\n",
    "                 spike_clusters,\n",
    "                 spike_templates,\n",
    "                 pc_feature_ind,\n",
    "                 pc_features,\n",
    "                 channels_to_use,\n",
    "                 subsample):\n",
    "\n",
    "    \"\"\" Return PC features for one unit\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    unit_id : Int\n",
    "        ID for this unit\n",
    "    spike_clusters : np.ndarray\n",
    "        Cluster labels for each spike\n",
    "    spike_templates : np.ndarry\n",
    "        Template labels for each spike\n",
    "    pc_feature_ind : np.ndarray\n",
    "        Channels used for PC calculation for each unit\n",
    "    pc_features : np.ndarray\n",
    "        Array of all PC features\n",
    "    channels_to_use : np.ndarray\n",
    "        Channels to use for calculating metrics\n",
    "    subsample : Int\n",
    "        maximum number of spikes to return\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    unit_PCs : numpy.ndarray (float)\n",
    "        PCs for one unit (num_spikes x num_PCs x num_channels)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    inds_for_unit = np.where(spike_clusters == unit_id)[0]\n",
    "\n",
    "    spikes_to_use = np.random.permutation(inds_for_unit)[:subsample]\n",
    "\n",
    "    unique_template_ids = np.unique(spike_templates[spikes_to_use])\n",
    "\n",
    "    unit_PCs = []\n",
    "\n",
    "    for template_id in unique_template_ids:\n",
    "\n",
    "        index_mask = spikes_to_use[np.squeeze(spike_templates[spikes_to_use]) == template_id]\n",
    "        these_inds = pc_feature_ind[template_id, :]\n",
    "\n",
    "        pc_array = []\n",
    "\n",
    "        for i in channels_to_use:\n",
    "\n",
    "            if np.isin(i, these_inds):\n",
    "                channel_index = np.argwhere(these_inds == i)[0][0]\n",
    "                pc_array.append(pc_features[index_mask, :, channel_index])\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        unit_PCs.append(np.stack(pc_array, axis=-1))\n",
    "\n",
    "    if len(unit_PCs) > 0:\n",
    "\n",
    "        return np.concatenate(unit_PCs)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dir = r\"F:\\EEG_exp\\mouse543396\\estim_vis1_2020-09-18_12-04-46\\experiment1\\probeC_sorted\\continuous\\Neuropix-3a-100.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use load_kilosort_data function to get all sorts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times, spike_clusters, spike_templates, amplitudes, templates, channel_map, clusterIDs, cluster_quality, pc_features, pc_feature_ind = \\\n",
    "            load_kilosort_data(rec_dir, 30000, use_master_clock = False, include_pcs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [Epoch('complete_session', 0, np.inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_units = len(np.unique(spike_clusters))\n",
    "total_epochs = len(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "[<ecephys_spike_sorting.ecephys_spike_sorting.common.epoch.Epoch object at 0x00000191125CCA58>]\n"
     ]
    }
   ],
   "source": [
    "print(total_units)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = epochs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_epoch = (spike_times > epoch.start_time) * (spike_times < epoch.end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate_pc_metrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calculate_pc_metrics(\n",
    "    spike_clusters[in_epoch],\n",
    "    spike_templates[in_epoch],\n",
    "    total_units,\n",
    "    pc_features[in_epoch,:,:],\n",
    "    pc_feature_ind,\n",
    "    params['num_channels_to_compare'], = 13\n",
    "    params['max_spikes_for_unit'], = 500\n",
    "    params['max_spikes_for_nn'], = 10000\n",
    "    params['n_neighbors'], = 4\n",
    "    do_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def of calculate_pc_metrics function\n",
    "spike_clusters = spike_clusters[in_epoch]\n",
    "spike_templates = spike_templates[in_epoch]\n",
    "# total_units = total_units\n",
    "pc_features = pc_features[in_epoch,:,:]\n",
    "# pc_feature_ind = pc_feature_ind\n",
    "num_channels_to_compare = 13\n",
    "max_spikes_for_cluster = 500\n",
    "max_spikes_for_nn = 10000\n",
    "n_neighbors = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "half_spread = int((num_channels_to_compare - 1) / 2)\n",
    "print(half_spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = np.unique(spike_clusters)\n",
    "template_ids = np.unique(spike_templates)\n",
    "\n",
    "template_peak_channels = np.zeros((len(template_ids),), dtype='uint16')\n",
    "cluster_peak_channels = np.zeros((len(cluster_ids),), dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, template_id in enumerate(template_ids):\n",
    "    for_template = np.squeeze(spike_templates == template_id)\n",
    "    pc_max = np.argmax(np.mean(pc_features[for_template, 0, :], 0))\n",
    "    template_peak_channels[idx] = pc_feature_ind[template_id, pc_max]\n",
    "\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    for_unit = np.squeeze(spike_clusters == cluster_id)\n",
    "    templates_for_unit = np.unique(spike_templates[for_unit])\n",
    "    template_positions = np.where(np.isin(template_ids, templates_for_unit))[0]\n",
    "    cluster_peak_channels[idx] = np.median(template_peak_channels[template_positions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate_pc_metrics_one_cluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calculate_pc_metrics_one_cluster)  # Function\n",
    "(\n",
    "    cluster_peak_channels, idx, cluster_id, cluster_ids,\n",
    "    half_spread, pc_features, pc_feature_ind,\n",
    "    spike_clusters, spike_templates,\n",
    "    max_spikes_for_cluster, max_spikes_for_nn, n_neighbors\n",
    ")\n",
    "for idx, cluster_id in enumerate(cluster_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = 478 ## have ahd problems with 47? and 478\n",
    "idx = np.squeeze(np.argwhere(cluster_ids == cluster_id))\n",
    "\n",
    "# cluster_peak_channels = cluster_peak_channels\n",
    "# idx = idx\n",
    "# cluster_id = cluster_id\n",
    "# cluster_ids = cluster_ids\n",
    "# half_spread\n",
    "# pc_features\n",
    "# pc_feature_ind\n",
    "# spike_clusters\n",
    "# spike_templates\n",
    "# max_spikes_for_cluster\n",
    "# max_spikes_for_nn\n",
    "# n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_channel = cluster_peak_channels[idx]\n",
    "num_spikes_in_cluster = np.sum(spike_clusters == cluster_id)\n",
    "\n",
    "half_spread_down = peak_channel \\\n",
    "    if peak_channel < half_spread \\\n",
    "    else half_spread\n",
    "\n",
    "half_spread_up = np.max(pc_feature_ind) - peak_channel \\\n",
    "    if peak_channel + half_spread > np.max(pc_feature_ind) \\\n",
    "    else half_spread\n",
    "\n",
    "channels_to_use = np.arange(peak_channel - half_spread_down, peak_channel + half_spread_up + 1)\n",
    "units_in_range = cluster_ids[np.isin(cluster_peak_channels, channels_to_use)]\n",
    "\n",
    "spike_counts = np.zeros(units_in_range.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7  34  35  38  39  40  41  42 475 476 478]\n"
     ]
    }
   ],
   "source": [
    "print(units_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx2, cluster_id2 in enumerate(units_in_range):\n",
    "    spike_counts[idx2] = np.sum(spike_clusters == cluster_id2)\n",
    "\n",
    "if num_spikes_in_cluster > max_spikes_for_cluster:\n",
    "    relative_counts = spike_counts / num_spikes_in_cluster * max_spikes_for_cluster\n",
    "else:\n",
    "    relative_counts = spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2742e+04 3.4920e+04 1.0851e+04 3.3390e+03 6.8300e+02 3.5100e+03\n",
      " 1.6837e+04 3.8470e+03 2.7000e+01 1.0310e+03 2.4660e+03]\n"
     ]
    }
   ],
   "source": [
    "print(spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pcs = np.zeros((0, pc_features.shape[1], channels_to_use.size))\n",
    "all_labels = np.zeros((0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx2, cluster_id2 in enumerate(units_in_range):\n",
    "\n",
    "    subsample = int(relative_counts[idx2])\n",
    "\n",
    "    pcs = get_unit_pcs(cluster_id2, spike_clusters, spike_templates,\n",
    "                       pc_feature_ind, pc_features, channels_to_use,\n",
    "                       subsample)\n",
    "\n",
    "    if pcs is not None and len(pcs.shape) == 3:\n",
    "\n",
    "        labels = np.ones((pcs.shape[0],)) * cluster_id2\n",
    "\n",
    "        all_pcs = np.concatenate((all_pcs, pcs),0)\n",
    "        all_labels = np.concatenate((all_labels, labels),0)\n",
    "\n",
    "all_pcs = np.reshape(all_pcs, (all_pcs.shape[0], pc_features.shape[1]*channels_to_use.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 39)\n"
     ]
    }
   ],
   "source": [
    "print(all_pcs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.\n",
      " 478. 478. 478. 478. 478. 478. 478. 478. 478. 478.]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)\n",
    "print(len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed, continue with d prime\n"
     ]
    }
   ],
   "source": [
    "if ((all_pcs.shape[0] > 10) and (cluster_id in all_labels) and (len(channels_to_use) > 0) and (len(units_in_range) > 1)):\n",
    "    print('Passed, continue with d prime')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d_prime = lda_metrics(all_pcs, all_labels, cluster_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbd_eeg",
   "language": "python",
   "name": "tbd_eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
