{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from glob import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import gspread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'C:\\Users\\lesliec\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbd_eeg.tbd_eeg.data_analysis.eegutils import EEGexp\n",
    "from tbd_eeg.tbd_eeg.data_analysis.Utilities.utilities import (\n",
    "    get_stim_events, get_evoked_traces, find_nearest_ind, qualitycheck_trials)\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CCF, 25 um resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 10:37:29,967 allensdk.api.api.retrieve_file_over_http INFO     Downloading URL: http://download.alleninstitute.org/informatics-archive/current-release/mouse_ccf/annotation/ccf_2017/annotation_25.nrrd\n"
     ]
    }
   ],
   "source": [
    "mcc = MouseConnectivityCache(resolution=25)\n",
    "str_tree = mcc.get_structure_tree()\n",
    "annot, annot_info = mcc.get_annotation_volume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Developed in NPX_find_bursts_testing.ipynb, this version is faster and only returns start times and spike counts ##\n",
    "## For thalamus ##\n",
    "def find_bursts_THunit(spike_times):\n",
    "    \n",
    "    preISIs = np.diff(spike_times)[:-1]\n",
    "    postISIs = np.diff(spike_times)[1:]\n",
    "    ## Find starts ##\n",
    "    bs_inds = np.nonzero((preISIs > 0.1) * (postISIs < 0.005))[0]\n",
    "    if len(bs_inds) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    burst_starts = bs_inds + 1 # +1 corrects for the actual spike ind\n",
    "    ## Loop through burst starts to find spikes that belong to the burst\n",
    "    burst_counts = []\n",
    "    for st_ind in bs_inds:\n",
    "        spkind = st_ind+1\n",
    "        bcount = 1\n",
    "        while (spkind < len(preISIs)) and (preISIs[spkind] < 0.004):\n",
    "            spkind += 1\n",
    "            bcount += 1\n",
    "        burst_counts.append(bcount)\n",
    "    \n",
    "    return spike_times[burst_starts], np.array(burst_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finds bursts in non-thalamic units ##\n",
    "def find_bursts_otherunit(spike_times):\n",
    "    ISI_threshold = 0.005 # ISI less than or equal to 5 ms\n",
    "    spike_count_thresh = 3 # at least this number of spikes to be considered burst\n",
    "\n",
    "    preISIs = np.insert(np.diff(spike_times), 0, 1.0)\n",
    "    burst_starts = []\n",
    "    burst_counts = []\n",
    "    spkind = 0\n",
    "    while spkind < len(spike_times):\n",
    "        tempevent = [spike_times[spkind]]\n",
    "        spkind += 1\n",
    "        while (spkind < len(spike_times)) and (preISIs[spkind] < ISI_threshold):\n",
    "            tempevent.append(spike_times[spkind])\n",
    "            spkind += 1\n",
    "        if len(tempevent) >= spike_count_thresh:\n",
    "            burst_starts.append(tempevent[0])\n",
    "            burst_counts.append(len(tempevent))\n",
    "        del tempevent\n",
    "    \n",
    "    return np.array(burst_starts), np.array(burst_counts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## From David Wyrick, 05.2025 ##\n",
    "def get_burst_events(spk_times, isi_interval=0.005, min_spikes=2, quiescence=0.1):\n",
    "    isi_min = 1.5/1000 #ms\n",
    "    #Get ISIs\n",
    "    isi = np.diff(spk_times)\n",
    " \n",
    "    #Get where bursts occur (e.g. ISI < 4ms)\n",
    "    burst_indices_all = np.where((isi <= isi_interval) & (isi >= isi_min))[0] #& (isi >= isi_min)\n",
    " \n",
    "    if len(burst_indices_all) == 0:\n",
    "        return [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan]\n",
    " \n",
    "    nISI_viol = np.sum(isi < isi_min)\n",
    "    nISI_burst = np.sum(isi <= isi_interval)\n",
    "    isi_viol_burst_frac = nISI_viol/nISI_burst\n",
    " \n",
    "    # if nISI_viol > 0:\n",
    "    #     print(f'ISI violation: {nISI_viol} spikes out of {nISI_burst} ISIs detected: {nISI_viol/nISI_burst:.3f} fraction')\n",
    " \n",
    "    #Subselect indices that begin each burst & get number of spikes per burst\n",
    "    tmp = np.diff(np.concatenate(([-1],burst_indices_all)))\n",
    "    indy = np.where(tmp > 1)[0]\n",
    "    burst_indices_s = burst_indices_all[indy]\n",
    "    burst_sizes = np.diff(np.concatenate((indy,[len(tmp)]))) + 1\n",
    "    burst_indices_e = burst_indices_s + burst_sizes - 1\n",
    " \n",
    "    #Calculate mean frequency for each burst\n",
    "    burst_freqs = np.array([1/np.mean(isi[i:j]) for i,j in zip(burst_indices_s,burst_indices_e)])\n",
    " \n",
    "    #Calculate number of bursts\n",
    "    num_bursts = [len(burst_sizes)]\n",
    " \n",
    "    #Apply minimum number of spikes criterion\n",
    "    indy = np.where(burst_sizes >= min_spikes)[0]\n",
    "    burst_indices_s = burst_indices_s[indy]\n",
    "    burst_sizes = burst_sizes[indy]\n",
    "    burst_freqs = burst_freqs[indy]\n",
    "    num_bursts.append(len(burst_sizes))\n",
    "    \n",
    "    #Apply queiscence criterion if necessary\n",
    "    indy = np.where(spk_times[burst_indices_s] - spk_times[burst_indices_s-1] > quiescence)[0]\n",
    "    burst_indices_s = burst_indices_s[indy]\n",
    "    burst_sizes = burst_sizes[indy]\n",
    "    burst_freqs = burst_freqs[indy]\n",
    "    num_bursts.append(len(burst_sizes))\n",
    " \n",
    "    #Get burst times\n",
    "    burst_spk_times = spk_times[burst_indices_s]\n",
    " \n",
    "    #Calculate burst lengths\n",
    "    burst_lengths = np.array([spk_times[iS + burst_sizes[ii] - 1] - spk_times[iS] for ii, iS in enumerate(burst_indices_s)])\n",
    " \n",
    "    return burst_spk_times, burst_indices_s, burst_sizes, burst_freqs, burst_lengths, num_bursts, isi_viol_burst_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_region(sunit_info, struct_tree, annot):\n",
    "    ## Finds a grey matter region above/below an unknown region ##\n",
    "    Vind = sunit_info.CCF_DV\n",
    "    vent_sip = struct_tree.get_structures_by_id([annot[sunit_info.CCF_AP, Vind, sunit_info.CCF_ML]])[0]['structure_id_path']\n",
    "    while not struct_tree.structure_descends_from(vent_sip[-1], 8):\n",
    "        Vind += 1\n",
    "        vent_sip = struct_tree.get_structures_by_id([annot[sunit_info.CCF_AP, Vind, sunit_info.CCF_ML]])[0]['structure_id_path']\n",
    "\n",
    "    Dind = sunit_info.CCF_DV\n",
    "    dors_sip = struct_tree.get_structures_by_id([annot[sunit_info.CCF_AP, Dind, sunit_info.CCF_ML]])[0]['structure_id_path']\n",
    "    while not struct_tree.structure_descends_from(dors_sip[-1], 8):\n",
    "        Dind -= 1\n",
    "        dors_sip = struct_tree.get_structures_by_id([annot[sunit_info.CCF_AP, Dind, sunit_info.CCF_ML]])[0]['structure_id_path']\n",
    "\n",
    "    if (Vind - sunit_info.CCF_DV) <= (sunit_info.CCF_DV - Dind):\n",
    "        return struct_tree.get_structures_by_id([vent_sip[-1]])[0]['acronym']\n",
    "    elif (Vind - sunit_info.CCF_DV) > (sunit_info.CCF_DV - Dind):\n",
    "        return struct_tree.get_structures_by_id([dors_sip[-1]])[0]['acronym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_from_children(test_id, parent_id, struct_tree):\n",
    "    try:\n",
    "        child_ind = np.nonzero([\n",
    "            struct_tree.structure_descends_from(test_id, x) for x in struct_tree.child_ids([parent_id])[0]\n",
    "        ])[0][0]\n",
    "        return struct_tree.get_structures_by_id([struct_tree.child_ids([parent_id])[0][child_ind]])[0]['acronym']\n",
    "    except:\n",
    "        return struct_tree.get_structures_by_id([parent_id])[0]['acronym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_region(region_acronym, struct_tree):\n",
    "    # areas_of_interest = {\n",
    "    #     'SM-TH': ['AV', 'CL', 'MD', 'PO', 'PF', 'VAL', 'VPL', 'VPM', 'VM'],\n",
    "    # }\n",
    "    \n",
    "    reg_id = struct_tree.get_structures_by_acronym([region_acronym])[0]['id']\n",
    "    if struct_tree.structure_descends_from(reg_id, 567):\n",
    "        if struct_tree.structure_descends_from(reg_id, 315):\n",
    "            return get_region_from_children(reg_id, 315, struct_tree)\n",
    "        elif struct_tree.structure_descends_from(reg_id, 698):\n",
    "            return 'OLF'\n",
    "        elif struct_tree.structure_descends_from(reg_id, 1089):\n",
    "            return get_region_from_children(reg_id, 1089, struct_tree)\n",
    "        elif struct_tree.structure_descends_from(reg_id, 703):\n",
    "            return get_region_from_children(reg_id, 703, struct_tree)\n",
    "        elif struct_tree.structure_descends_from(reg_id, 477):\n",
    "            return 'STR'\n",
    "        elif struct_tree.structure_descends_from(reg_id, 803):\n",
    "            return 'PAL'\n",
    "        else:\n",
    "            return 'unassigned'\n",
    "    elif struct_tree.structure_descends_from(reg_id, 343):\n",
    "        if struct_tree.structure_descends_from(reg_id, 1129):\n",
    "            return 'TH'\n",
    "            # if region_acronym == 'RT':\n",
    "            #     return 'RT-TH'\n",
    "            # elif region_acronym in areas_of_interest['SM-TH']:\n",
    "            #     return 'SM-TH'\n",
    "            # else:\n",
    "            #     return 'other-TH'\n",
    "        elif struct_tree.structure_descends_from(reg_id, 1097):\n",
    "            return 'HY'\n",
    "        else:\n",
    "            return get_region_from_children(reg_id, 343, struct_tree)\n",
    "    else:\n",
    "        return 'unassigned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_parent_region_to_df(unit_info_df, struct_tree, annot):\n",
    "    ## First, make sure all names in region column correspond to a CCF region (removes nan values) ##\n",
    "    adj_regions = unit_info_df['region'].values.copy()\n",
    "    for indi, rowi in unit_info_df.iterrows():\n",
    "        try:\n",
    "            str_info = struct_tree.get_structures_by_acronym([rowi.region])[0]\n",
    "        except KeyError:\n",
    "            if rowi.depth <= 0: # unit was placed above brain\n",
    "                new_region_id = annot[rowi.CCF_AP, np.nonzero(annot[rowi.CCF_AP, :, rowi.CCF_ML])[0][0], rowi.CCF_ML]\n",
    "                adj_regions[indi] = struct_tree.get_structures_by_id([new_region_id])[0]['acronym']\n",
    "            else:\n",
    "                Lind = rowi.CCF_ML\n",
    "                while annot[rowi.CCF_AP, rowi.CCF_DV, Lind] == 0:\n",
    "                    Lind -= 1\n",
    "                new_region_id = struct_tree.get_structures_by_id(\n",
    "                    [annot[rowi.CCF_AP, rowi.CCF_DV, Lind]])[0]['structure_id_path'][-1]\n",
    "                adj_regions[indi] = struct_tree.get_structures_by_id([new_region_id])[0]['acronym']\n",
    "    unit_info_df['adj_region'] = adj_regions\n",
    "    \n",
    "    ## Second, re-assign any non-grey matter areas to the closest region ##\n",
    "    adj_regions = unit_info_df['adj_region'].values.copy()\n",
    "    for indi, rowi in unit_info_df.iterrows():\n",
    "        reg_id = struct_tree.get_structures_by_acronym([rowi.adj_region])[0]['id']\n",
    "        if not struct_tree.structure_descends_from(reg_id, 8):\n",
    "            adj_regions[indi] = find_closest_region(rowi, struct_tree, annot)\n",
    "    unit_info_df['adj_region'] = adj_regions\n",
    "    \n",
    "    ## Finally, assign a parent region to each adjusted CCF region ##\n",
    "    parent_regions = unit_info_df['adj_region'].values.copy()\n",
    "    for indi, rowi in unit_info_df.iterrows():\n",
    "        parent_regions[indi] = get_parent_region(rowi.adj_region, struct_tree)\n",
    "    unit_info_df['parent_region'] = parent_regions\n",
    "    \n",
    "    return unit_info_df.drop('adj_region', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load subjects.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multisub_file = r\"C:\\Users\\lesliec\\OneDrive - Allen Institute\\analysis\\GAT1-KO_analyses\\GAT1_control_NPephys_subjects.csv\"\n",
    "all_sessions_df = pd.read_csv(multisub_file, converters={'mouse': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genotype</th>\n",
       "      <th>mouse</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sweep_states</th>\n",
       "      <th>bad_chs</th>\n",
       "      <th>CCFres</th>\n",
       "      <th>NPX_analysis</th>\n",
       "      <th>EEG_analysis</th>\n",
       "      <th>data_loc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAT1-KO</td>\n",
       "      <td>645606</td>\n",
       "      <td>EEGNPXspont_estim_2022-12-20_12-26-39</td>\n",
       "      <td>awake</td>\n",
       "      <td>none</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>E:\\GAT1_EEG_pilot\\mouse645606\\EEGNPXspont_esti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAT1-KO</td>\n",
       "      <td>644565</td>\n",
       "      <td>EEGNPXspont_estim_2022-12-22_10-36-08</td>\n",
       "      <td>awake</td>\n",
       "      <td>none</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>E:\\GAT1_EEG_pilot\\mouse644565\\EEGNPXspont_esti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAT1-KO</td>\n",
       "      <td>672785</td>\n",
       "      <td>EEGNPXspont_estim_2023-07-05_12-39-59</td>\n",
       "      <td>awake</td>\n",
       "      <td>all</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>E:\\GAT1_EEG_pilot\\mouse672785\\EEGNPXspont_esti...</td>\n",
       "      <td>EEG has low amplitude signals and all chs look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GAT1-KO</td>\n",
       "      <td>672789</td>\n",
       "      <td>EEGNPXspont_estim_2023-07-13_13-28-01</td>\n",
       "      <td>awake</td>\n",
       "      <td>none</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>E:\\GAT1_EEG_pilot\\mouse672789\\EEGNPXspont_esti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wildtype</td>\n",
       "      <td>654181</td>\n",
       "      <td>estim_vis_2022-11-22_09-42-58</td>\n",
       "      <td>awake,isoflurane</td>\n",
       "      <td>7,8,11,13</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>F:\\psi_exp\\mouse654181\\estim_vis_2022-11-22_09...</td>\n",
       "      <td>good control mouse with RT units</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genotype   mouse                             experiment      sweep_states  \\\n",
       "0   GAT1-KO  645606  EEGNPXspont_estim_2022-12-20_12-26-39             awake   \n",
       "1   GAT1-KO  644565  EEGNPXspont_estim_2022-12-22_10-36-08             awake   \n",
       "2   GAT1-KO  672785  EEGNPXspont_estim_2023-07-05_12-39-59             awake   \n",
       "3   GAT1-KO  672789  EEGNPXspont_estim_2023-07-13_13-28-01             awake   \n",
       "4  wildtype  654181          estim_vis_2022-11-22_09-42-58  awake,isoflurane   \n",
       "\n",
       "     bad_chs  CCFres  NPX_analysis  EEG_analysis  \\\n",
       "0       none      25          True          True   \n",
       "1       none      25          True          True   \n",
       "2        all      25          True         False   \n",
       "3       none      25          True          True   \n",
       "4  7,8,11,13      25          True          True   \n",
       "\n",
       "                                            data_loc  \\\n",
       "0  E:\\GAT1_EEG_pilot\\mouse645606\\EEGNPXspont_esti...   \n",
       "1  E:\\GAT1_EEG_pilot\\mouse644565\\EEGNPXspont_esti...   \n",
       "2  E:\\GAT1_EEG_pilot\\mouse672785\\EEGNPXspont_esti...   \n",
       "3  E:\\GAT1_EEG_pilot\\mouse672789\\EEGNPXspont_esti...   \n",
       "4  F:\\psi_exp\\mouse654181\\estim_vis_2022-11-22_09...   \n",
       "\n",
       "                                               notes  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  EEG has low amplitude signals and all chs look...  \n",
       "3                                                NaN  \n",
       "4                   good control mouse with RT units  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sessions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.bool_"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_sessions_df.iloc[0].NPX_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check trial quality for EEG signals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for mouse, explist in subjects.items():\n",
    "    for exptype, dataloc in explist.items():\n",
    "        print('{}: {}'.format(mouse, exptype))\n",
    "        exp = EEGexp(dataloc, preprocess=False, make_stim_csv=False)\n",
    "        \n",
    "        ## Load stim log ##\n",
    "        stim_log = pd.read_csv(exp.stimulus_log_file).astype({'parameter': str})\n",
    "        if 'good' not in stim_log.columns:\n",
    "            if np.any([True for x in exp.experiment_data if 'recording' in x]):\n",
    "                ## Grab exp metadata from Templeton-log_exp ##\n",
    "                exp_meta = metadata[(\n",
    "                    (metadata['mouse_name'].str.contains(mouse)) &\n",
    "                    (metadata['exp_name'].str.contains(os.path.basename(os.path.dirname(exp.experiment_folder))))\n",
    "                )].squeeze()\n",
    "                badchstr = exp_meta['EEG bad_channels'].replace(' ','')\n",
    "                if badchstr == 'all':\n",
    "                    print(' All EEG chs are bad, marking all trials as \"good\".')\n",
    "                    stim_log['good'] = [True] * len(stim_log)\n",
    "                    stim_log.to_csv(exp.stimulus_log_file, index=False)\n",
    "                else:\n",
    "                    print(' Checking trial quality...')\n",
    "                    bad_chs = []\n",
    "                    for char in badchstr.split(','):\n",
    "                        if char.isdecimal():\n",
    "                            bad_chs.append(int(char))\n",
    "                    qualitycheck_trials(exp, known_bad_chs=bad_chs)\n",
    "            else:\n",
    "                print(' Experiment has no EEG, making all trials \"good\".')\n",
    "                stim_log['good'] = [True] * len(stim_log)\n",
    "                stim_log.to_csv(exp.stimulus_log_file, index=False)\n",
    "        else:\n",
    "            print(' Stim_log already has trial quality, skipping.')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_existing_files = True\n",
    "\n",
    "event_window = [-2.0, 2.0]\n",
    "\n",
    "apply_mask = True\n",
    "apply_hpass = True\n",
    "apply_lpass = True\n",
    "\n",
    "spike_count_threshold = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process running signal and EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645606: EEGNPXspont_estim_2022-12-20_12-26-39\n",
      "Experiment type: electrical stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving E:\\GAT1_EEG_pilot\\mouse645606\\EEGNPXspont_estim_2022-12-20_12-26-39\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "644565: EEGNPXspont_estim_2022-12-22_10-36-08\n",
      "Experiment type: electrical stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving E:\\GAT1_EEG_pilot\\mouse644565\\EEGNPXspont_estim_2022-12-22_10-36-08\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "672785: EEGNPXspont_estim_2023-07-05_12-39-59\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving E:\\GAT1_EEG_pilot\\mouse672785\\EEGNPXspont_estim_2023-07-05_12-39-59\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "672789: EEGNPXspont_estim_2023-07-13_13-28-01\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving E:\\GAT1_EEG_pilot\\mouse672789\\EEGNPXspont_estim_2023-07-13_13-28-01\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "654181: estim_vis_2022-11-22_09-42-58\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse654181\\estim_vis_2022-11-22_09-42-58\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "669118: pilot_aw_2023-03-23_12-14-39\n",
      "Experiment type: electrical stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse669118\\pilot_aw_2023-03-23_12-14-39\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "669117: pilot_aw_2023-03-29_11-09-15\n",
      "Experiment type: electrical stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse669117\\pilot_aw_2023-03-29_11-09-15\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "569064: estim_vis_2021-04-08_10-28-24\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\ZZmanuscript_eLife\\mouse569064\\estim_vis_2021-04-08_10-28-24\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "569068: estim_vis_2021-03-04_10-51-38\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\ZZmanuscript_eLife\\mouse569068\\estim_vis_2021-03-04_10-51-38\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "666196: pilot_aw_2023-03-15_12-29-06\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse666196\\pilot_aw_2023-03-15_12-29-06\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "655956: estim_2022-12-15_10-07-59\n",
      "Experiment type: electrical stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse655956\\estim_2022-12-15_10-07-59\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "689239: aw_iso_2023-08-09_11-15-42\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse689239\\aw_iso_2023-08-09_11-15-42\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "703063: aw_psi_2023-11-15_11-08-12\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse703063\\aw_psi_2023-11-15_11-08-12\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "703064: aw_iso_2023-11-29_11-23-30\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse703064\\aw_iso_2023-11-29_11-23-30\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "709401: aw_iso_2023-12-13_09-55-07\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse709401\\aw_iso_2023-12-13_09-55-07\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "709400: aw_iso_2024-01-31_11-35-57\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse709400\\aw_iso_2024-01-31_11-35-57\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "730913: aw_sal_2024-04-24_10-43-30\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse730913\\aw_sal_2024-04-24_10-43-30\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n",
      "730911: aw_sal_2024-05-01_11-57-16\n",
      "Experiment type: electrical and sensory stimulation\n",
      "  Getting event-related running...\n",
      "  Loading EEG data...\n",
      "  Getting EEG traces...\n",
      "   ...saving F:\\psi_exp\\mouse730911\\aw_sal_2024-05-01_11-57-16\\experiment1\\recording1\\evoked_data\\event_EEGtraces.npy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rowi, exprow in all_sessions_df.iterrows():\n",
    "    print('{}: {}'.format(exprow.mouse, exprow.experiment))\n",
    "    exp = EEGexp(exprow.data_loc, preprocess=False, make_stim_csv=False)\n",
    "\n",
    "    ## Set file names ##\n",
    "    running_file = os.path.join(exp.data_folder, 'running_signal.npy')\n",
    "    raw_running_file = os.path.join(exp.data_folder, 'raw_running_signal.npy')\n",
    "    running_ts_file = os.path.join(exp.data_folder, 'running_timestamps_master_clock.npy')\n",
    "    evoked_folder = os.path.join(exp.data_folder, 'evoked_data')\n",
    "    if not os.path.exists(evoked_folder):\n",
    "        os.mkdir(evoked_folder)\n",
    "    event_running_file = os.path.join(evoked_folder, 'event_running_speed.npy')\n",
    "    event_running_ts_file = os.path.join(evoked_folder, 'event_running_times.npy')\n",
    "    event_EEGtraces_file = os.path.join(evoked_folder, 'event_EEGtraces.npy')\n",
    "    event_EEGtraces_ts_file = os.path.join(evoked_folder, 'event_EEGtraces_times.npy')\n",
    "\n",
    "    ## Load stim log ##\n",
    "    stim_log = pd.read_csv(exp.stimulus_log_file)\n",
    "    all_event_times = stim_log['onset'].values\n",
    "        \n",
    "    ## Load running signal and get mean event speed ##\n",
    "    if os.path.exists(running_file):\n",
    "        run_signal = np.load(running_file)\n",
    "        run_timestamps = np.load(running_ts_file)\n",
    "    else:\n",
    "        print('  Loading running from sync and saving...')\n",
    "        run_signal, raw_speed, run_timestamps = exp.load_running()\n",
    "        np.save(running_file, run_signal, allow_pickle=False)\n",
    "        np.save(raw_running_file, raw_speed, allow_pickle=False)\n",
    "        np.save(running_ts_file, run_timestamps, allow_pickle=False)\n",
    "    if not os.path.exists(event_running_file) or overwrite_existing_files:\n",
    "        print('  Getting event-related running...')\n",
    "        rinds = np.arange(-int(-event_window[0] * 100), int(event_window[1] * 100))\n",
    "        event_inds = np.array([find_nearest_ind(run_timestamps, x) for x in all_event_times])\n",
    "        event_run_speed = run_signal[np.repeat([rinds], len(event_inds), axis=0).T + event_inds]\n",
    "        event_run_times = rinds / 100\n",
    "        ## Save ##\n",
    "        np.save(event_running_file, event_run_speed, allow_pickle=False)\n",
    "        np.save(event_running_ts_file, event_run_times, allow_pickle=False)\n",
    "        ## Add speed to stim_log ##\n",
    "        evinds = np.nonzero((event_run_times >= -0.5) & (event_run_times < 0.5))[0]\n",
    "        mean_speed = np.mean(event_run_speed[evinds, :], axis=0)\n",
    "        stim_log['mean_speed'] = mean_speed\n",
    "        stim_log['resting_trial'] = stim_log['mean_speed'] == 0\n",
    "        stim_log.to_csv(exp.stimulus_log_file, index=False)\n",
    "        \n",
    "    if np.any([True for x in exp.experiment_data if 'recording' in x]):\n",
    "        # badchstr = exprow['bad_chs'].replace(' ','')\n",
    "        # if (not os.path.exists(event_EEGtraces_file) or overwrite_existing_files) and (badchstr != 'all'):\n",
    "        if (not os.path.exists(event_EEGtraces_file) or overwrite_existing_files):\n",
    "            ## Load EEG data and preprocess ##\n",
    "            print('  Loading EEG data...')\n",
    "            datai, tsi = exp.load_eegdata()\n",
    "            eeg_chs = np.arange(0, datai.shape[1])\n",
    "\n",
    "            ## Mask estim artifact ##\n",
    "            if apply_mask:\n",
    "                mask_samples = int(0.002 * exp.ephys_params['EEG']['sample_rate'])\n",
    "                for etime in stim_log.loc[stim_log['stim_type'] == 'biphasic', 'onset'].to_numpy():\n",
    "                    val = find_nearest_ind(tsi, etime) - 2\n",
    "                    datai[val:val+mask_samples, :] = datai[val:val-mask_samples:-1, :]\n",
    "\n",
    "            ## Apply high-pass filter ##\n",
    "            if apply_hpass:\n",
    "                hpb, hpa = signal.butter(3, 0.1/(exp.ephys_params['EEG']['sample_rate']/2), btype='highpass')\n",
    "                datai = signal.filtfilt(hpb, hpa, datai, axis=0)\n",
    "\n",
    "            ## Get evoked traces ##\n",
    "            print('  Getting EEG traces...')\n",
    "            event_traces, event_ts = get_evoked_traces(\n",
    "                datai, tsi, all_event_times, -event_window[0], event_window[1], exp.ephys_params['EEG']['sample_rate'])\n",
    "\n",
    "            ## Apply lowpass filter ##\n",
    "            if apply_lpass:\n",
    "                lpb, lpa = signal.butter(3, 100/(exp.ephys_params['EEG']['sample_rate']/2), btype='low')\n",
    "                event_traces = signal.filtfilt(lpb, lpa, event_traces, axis=0)\n",
    "\n",
    "            ## Save ##\n",
    "            print('   ...saving {}.'.format(event_EEGtraces_file))\n",
    "            np.save(event_EEGtraces_file, event_traces, allow_pickle=False)\n",
    "            np.save(event_EEGtraces_ts_file, event_ts, allow_pickle=False)\n",
    "        else:\n",
    "            print('  Not creating EEG traces file, it already exists or all EEG chs are bad.')\n",
    "    else:\n",
    "        print('  No EEG in this recording.')\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645606: EEGNPXspont_estim_2022-12-20_12-26-39\n",
      "Experiment type: electrical stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 1.53 min\n",
      "\n",
      "644565: EEGNPXspont_estim_2022-12-22_10-36-08\n",
      "Experiment type: electrical stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 1.44 min\n",
      "\n",
      "672785: EEGNPXspont_estim_2023-07-05_12-39-59\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 5.80 min\n",
      "\n",
      "672789: EEGNPXspont_estim_2023-07-13_13-28-01\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 4.28 min\n",
      "\n",
      "654181: estim_vis_2022-11-22_09-42-58\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 2.94 min\n",
      "\n",
      "669118: pilot_aw_2023-03-23_12-14-39\n",
      "   Not analyzing probes on this session (NPX_analysis=False).\n",
      "\n",
      "669117: pilot_aw_2023-03-29_11-09-15\n",
      "   Not analyzing probes on this session (NPX_analysis=False).\n",
      "\n",
      "569064: estim_vis_2021-04-08_10-28-24\n",
      "   Not analyzing probes on this session (NPX_analysis=False).\n",
      "\n",
      "569068: estim_vis_2021-03-04_10-51-38\n",
      "   Not analyzing probes on this session (NPX_analysis=False).\n",
      "\n",
      "666196: pilot_aw_2023-03-15_12-29-06\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 20.68 min\n",
      "\n",
      "655956: estim_2022-12-15_10-07-59\n",
      "Experiment type: electrical stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 3.30 min\n",
      "\n",
      "689239: aw_iso_2023-08-09_11-15-42\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 5.22 min\n",
      "\n",
      "703063: aw_psi_2023-11-15_11-08-12\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 6.35 min\n",
      "\n",
      "703064: aw_iso_2023-11-29_11-23-30\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 3.55 min\n",
      "\n",
      "709401: aw_iso_2023-12-13_09-55-07\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 4.60 min\n",
      "\n",
      "709400: aw_iso_2024-01-31_11-35-57\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 5.02 min\n",
      "\n",
      "730913: aw_sal_2024-04-24_10-43-30\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 9.74 min\n",
      "\n",
      "730911: aw_sal_2024-05-01_11-57-16\n",
      "Experiment type: electrical and sensory stimulation\n",
      " Getting probe info...\n",
      "  probeB\n",
      "  probeC\n",
      "  probeD\n",
      "  probeF\n",
      "   Time to get unit spike times and save: 7.19 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rowi, exprow in all_sessions_df.iterrows():\n",
    "    print('{}: {}'.format(exprow.mouse, exprow.experiment))\n",
    "    if not exprow.NPX_analysis:\n",
    "        print('   Not analyzing probes on this session (NPX_analysis=False).\\n')\n",
    "        continue\n",
    "    exp = EEGexp(exprow.data_loc, preprocess=False, make_stim_csv=False)\n",
    " \n",
    "    probe_list = [x.replace('_sorted', '') for x in exp.experiment_data if 'probe' in x]\n",
    "    if len(probe_list) == 0:\n",
    "        print('  This experiment has no probe data, not making spike times files.\\n')\n",
    "        continue\n",
    "    \n",
    "    ## Set file names ##\n",
    "    evoked_folder = os.path.join(exp.data_folder, 'evoked_data')\n",
    "    if not os.path.exists(evoked_folder):\n",
    "        os.mkdir(evoked_folder)\n",
    "    unit_info_file = os.path.join(evoked_folder, 'all_units_info.csv')\n",
    "    unit_allspiketimes_file = os.path.join(evoked_folder, 'units_allspikes.pkl')\n",
    "    unit_eventspikes_file = os.path.join(evoked_folder, 'units_event_spikes.pkl')\n",
    "    if overwrite_existing_files:\n",
    "        pass # will overwrite all subjects' files\n",
    "    else:\n",
    "        if os.path.exists(unit_info_file):\n",
    "            print('  {} already exists, skipping analysis.\\n'.format(unit_info_file))\n",
    "            continue\n",
    "\n",
    "    ## Load stim log ##\n",
    "    stim_log = pd.read_csv(exp.stimulus_log_file)\n",
    "    all_event_times = stim_log['onset'].values\n",
    "\n",
    "    ## Get probe info ##\n",
    "    print(' Getting probe info...')\n",
    "    start = time.time()\n",
    "    all_units_info = []\n",
    "    unit_allspiketimes = {}\n",
    "    unit_eventspikestimes = {'event_window': event_window, 'event_spikes': {}, 'event_bursts': {}}\n",
    "    for probe_name in probe_list:\n",
    "        print('  {}'.format(probe_name))\n",
    "        ## Load probe_info.json ##\n",
    "        with open(exp.ephys_params[probe_name]['probe_info']) as data_file:\n",
    "            data = json.load(data_file)\n",
    "        npx_allch = np.array(data['channel'])\n",
    "        surface_ch = int(data['surface_channel'])\n",
    "        allch_z = np.array(data['vertical_pos'])\n",
    "        # ref_mask = np.array(data['mask'])\n",
    "        # npx_chs = np.array([x for x in npx_allch if ref_mask[x] and x <= surface_ch])\n",
    "        probe_ch_depths = allch_z[surface_ch] - allch_z\n",
    "        \n",
    "        ## Load the unit info ##\n",
    "        cluster_group = pd.read_csv(exp.ephys_params[probe_name]['cluster_group'], sep='\\t')\n",
    "        cluster_metrics = pd.read_csv(exp.ephys_params[probe_name]['cluster_metrics'])\n",
    "        spike_clusters = np.load(exp.ephys_params[probe_name]['spike_clusters'])\n",
    "        spike_times = np.load(exp.ephys_params[probe_name]['spike_times'])\n",
    "        \n",
    "        if not np.array_equal(cluster_group['cluster_id'].values.astype('int'), np.unique(spike_clusters)):\n",
    "            print('   IDs from cluster_group.tsv DO NOT match spike_clusters.npy. This may mean there are unsorted units, check in phy.')\n",
    "            continue\n",
    "        if np.array_equal(cluster_group['cluster_id'].values.astype('int'), cluster_metrics['cluster_id'].values.astype('int')):\n",
    "            unit_metrics = pd.merge(cluster_group.rename(columns={'group':'label'}), cluster_metrics, on='cluster_id')\n",
    "        else:\n",
    "            print('   IDs from cluster_group DO NOT match cluster_metrics.')\n",
    "            continue\n",
    "        \n",
    "        ## Select only \"good\" units ##\n",
    "        unit_metrics['spike_count'] = [np.sum(spike_clusters == x) for x in unit_metrics.cluster_id.values]\n",
    "        good_units = unit_metrics[(unit_metrics['label'] == 'good') & (unit_metrics['spike_count'] > spike_count_threshold)]\n",
    "        tempcoords = np.array([[int(y) for y in x.replace('[','').replace(']','').replace(' ','').split(',')] for x in good_units.ccf_coord.values])\n",
    "        \n",
    "        ## Now reorganize metrics to save ##\n",
    "        probe_units = pd.DataFrame([probe_name[-1] + str(x) for x in good_units.cluster_id.values], columns=['unit_id'])\n",
    "        probe_units['probe'] = [probe_name] * len(good_units)\n",
    "        probe_units['peak_ch'] = good_units['peak_channel'].values\n",
    "        probe_units['depth'] = [probe_ch_depths[pkch] for pkch in good_units.peak_channel.values]\n",
    "        probe_units['spike_duration'] = good_units['duration'].values\n",
    "        probe_units['region'] = good_units['area'].values\n",
    "        probe_units['CCF_AP'], probe_units['CCF_DV'], probe_units['CCF_ML'] = tempcoords[:,0], tempcoords[:,1], tempcoords[:,2]\n",
    "        probe_units['firing_rate'] = good_units['firing_rate'].values\n",
    "        probe_units['presence_ratio'] = good_units['presence_ratio'].values\n",
    "        probe_units['isi_viol'] = good_units['isi_viol'].values\n",
    "        probe_units['amplitude_cutoff'] = good_units['amplitude_cutoff'].values\n",
    "        probe_units['spike_count'] = good_units['spike_count'].values\n",
    "        \n",
    "        ## Add parent region column ##\n",
    "        probe_units = add_parent_region_to_df(probe_units, str_tree, annot)\n",
    "        all_units_info.append(probe_units)\n",
    "\n",
    "        for uniti, (uind, unitrow) in zip(good_units.cluster_id.values, probe_units.iterrows()):\n",
    "            spikesi = np.squeeze(spike_times[spike_clusters == uniti])\n",
    "            if unitrow.parent_region == 'TH':\n",
    "                burstsi, burst_counts = find_bursts_THunit(spikesi)\n",
    "            else:\n",
    "                burstsi, burst_counts = find_bursts_otherunit(spikesi)\n",
    "            unit_allspiketimes[unitrow.unit_id] = {\n",
    "                'spikes': spikesi,\n",
    "                'bursts': burstsi,\n",
    "                'burst_counts': burst_counts,\n",
    "            }\n",
    "\n",
    "            event_raster = []\n",
    "            burst_raster = []\n",
    "            burst_count_raster = []\n",
    "            for eventi in all_event_times:\n",
    "                spikeinds = np.nonzero((spikesi >= eventi + event_window[0]) & (spikesi <= eventi + event_window[1]))[0]\n",
    "                event_raster.append(spikesi[spikeinds] - eventi)\n",
    "                burstinds = np.nonzero((burstsi >= eventi + event_window[0]) & (burstsi <= eventi + event_window[1]))[0]\n",
    "                burst_raster.append(burstsi[burstinds] - eventi)\n",
    "                burst_count_raster.append(burst_counts[burstinds])\n",
    "            unit_eventspikestimes['event_spikes'][unitrow.unit_id] = event_raster\n",
    "            unit_eventspikestimes['event_bursts'][unitrow.unit_id] = {'times': burst_raster, 'counts': burst_count_raster}\n",
    "\n",
    "    ## Now combine all probe units dfs ##\n",
    "    all_units_info_df = pd.concat(all_units_info, ignore_index=True)\n",
    "    all_units_info_df.to_csv(unit_info_file, index=False)\n",
    "    pickle.dump(unit_allspiketimes, open(unit_allspiketimes_file, 'wb'))\n",
    "    pickle.dump(unit_eventspikestimes, open(unit_eventspikes_file, 'wb'))\n",
    "\n",
    "    end = time.time()\n",
    "    print('   Time to get unit spike times and save: {:.2f} min\\n'.format((end-start)/60))\n",
    "    ## After each subject, delete common variables ##\n",
    "    del probe_units, all_units_info, all_units_info_df, unit_allspiketimes, stim_log, all_event_times, unit_eventspikestimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0\n"
     ]
    }
   ],
   "source": [
    "print(unitrow.unit_id)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(np.unique(all_units_info_df['region'].values.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbd_eeg",
   "language": "python",
   "name": "tbd_eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
